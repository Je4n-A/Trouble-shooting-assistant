{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Trouble-shooting-assistant\\.venv\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:328: UserWarning: Multiple active versions of the dataset matching the name credit-g exist. Versions may be fundamentally different, returning version 1. Available versions:\n",
      "- version 1, status: active\n",
      "  url: https://www.openml.org/search?type=data&id=31\n",
      "- version 2, status: active\n",
      "  url: https://www.openml.org/search?type=data&id=44096\n",
      "\n",
      "  warn(warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 21)\n",
      "int64       7\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "Name: count, dtype: int64\n",
      "class\n",
      "good    700\n",
      "bad     300\n",
      "Name: count, dtype: int64\n",
      "class\n",
      "good    70.0\n",
      "bad     30.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# import neccessary libraries\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "data = fetch_openml(\"credit-g\", as_frame=True, parser=\"auto\")\n",
    "df = pd.concat([data.data, data.target.rename(\"class\")], axis=1)\n",
    "\n",
    "X = df.drop(columns=[\"class\"])\n",
    "y = df[\"class\"]\n",
    "\n",
    "print(df.shape)                 # expect (1000, 21)\n",
    "print(X.dtypes.value_counts())  # see mix of categories/numerics\n",
    "print(y.value_counts())         # counts\n",
    "print((y.value_counts(normalize=True)*100).round(2))  # percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (800, 20)\n",
      "X_valid (200, 20)\n",
      "y_train (800,)\n",
      "y_valid (200,)\n"
     ]
    }
   ],
   "source": [
    "# stratified train/validation split (80/20)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "for name, arr in [(\"X_train\", X_train), (\"X_valid\", X_valid),\n",
    "                  (\"y_train\", y_train), (\"y_valid\", y_valid)]:\n",
    "    print(name, arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc153a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 categorical\n",
      "7 numeric\n",
      "['checking_status', 'credit_history', 'purpose', 'savings_status', 'employment', 'personal_status', 'other_parties', 'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker']\n"
     ]
    }
   ],
   "source": [
    "# Identifying which features are categorical vs numeric for X_train\n",
    "\n",
    "cat_cols = X_train.select_dtypes(include=['category','object']).columns.tolist()\n",
    "num_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print(len(cat_cols), \"categorical\"); print(len(num_cols), \"numeric\")\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "252680a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "cat_cols = ['checking_status','credit_history','purpose','savings_status','employment',\n",
    "            'personal_status','other_parties','property_magnitude','other_payment_plans',\n",
    "            'housing','job','own_telephone','foreign_worker']\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "])\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "proba_valid = clf.predict_proba(X_valid)\n",
    "idx_bad = list(clf.named_steps[\"model\"].classes_).index(\"bad\")\n",
    "p_bad = proba_valid[:, idx_bad]\n",
    "\n",
    "auc = roc_auc_score((y_valid==\"bad\").astype(int), p_bad)\n",
    "print(\"Validation ROC-AUC:\", round(auc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c56bb73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786 0.019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "y_bad = (y == \"bad\").astype(int)  # 1 = bad (positive class), 0 = good\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(clf, X, y_bad, cv=cv, scoring=\"roc_auc\")\n",
    "print(scores.mean().round(3), scores.std().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ee1089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.791 0.022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400, random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "rf_clf = Pipeline([(\"prep\", preprocess), (\"model\", rf)])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(rf_clf, X, y_bad, cv=cv, scoring=\"roc_auc\")\n",
    "print(scores.mean().round(3), scores.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b5148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20500000000000002 [[77 63]\n",
      " [ 6 54]]\n",
      "Precision: 0.46153846153846156\n",
      "Recall: 0.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "y_true = (y_valid==\"bad\").astype(int)\n",
    "best = (None, 1e18)  # (t, cost)\n",
    "for t in np.linspace(0,1,201):\n",
    "    y_pred = (p_bad >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    cost = fp*1 + fn*5\n",
    "    if cost < best[1]:\n",
    "        best = (t, cost)\n",
    "t_star = best[0]\n",
    "y_hat = (p_bad >= t_star).astype(int)\n",
    "print(t_star, confusion_matrix(y_true, y_hat))\n",
    "print(\"Precision:\", precision_score(y_true, y_hat))\n",
    "print(\"Recall:\", recall_score(y_true, y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4611c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost@0.5 = 190 cmat: [[np.int64(115), np.int64(25)], [np.int64(33), np.int64(27)]]\n",
      "51.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = (y_valid==\"bad\").astype(int)\n",
    "y_hat_05 = (p_bad >= 0.5).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_hat_05).ravel()\n",
    "print(\"cost@0.5 =\", fp + 5*fn, \"cmat:\", [[tn,fp],[fn,tp]])\n",
    "cost_default = 190\n",
    "cost_opt = 93\n",
    "reduction_pct = (cost_default - cost_opt) / cost_default * 100\n",
    "print(round(reduction_pct, 1))  # â†’ 51.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87118a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top risk-increasing (OR>1):\n",
      "                                      feature  odds_ratio\n",
      "                             purpose_used car    3.871150\n",
      "                  checking_status_no checking    2.712682\n",
      "                      other_parties_guarantor    2.670500\n",
      "credit_history_critical/other existing credit    2.324341\n",
      "                            foreign_worker_no    2.053430\n",
      "\n",
      "Top protective (OR<1):\n",
      "                   feature  odds_ratio\n",
      "         purpose_education    0.493475\n",
      "           purpose_new car    0.506342\n",
      "        checking_status_<0    0.508079\n",
      "       savings_status_<100    0.587095\n",
      "other_parties_co applicant    0.599541\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pre = clf.named_steps[\"prep\"]\n",
    "ohe = pre.named_transformers_[\"cat\"]\n",
    "# Feature names (version-safe)\n",
    "try:\n",
    "    cat_feats = ohe.get_feature_names_out(cat_cols)\n",
    "except:\n",
    "    cat_feats = ohe.get_feature_names(cat_cols)\n",
    "feat_names = list(num_cols) + list(cat_feats)\n",
    "\n",
    "coef = clf.named_steps[\"model\"].coef_.ravel()\n",
    "or_df = pd.DataFrame({\"feature\": feat_names, \"odds_ratio\": np.exp(coef)})\n",
    "\n",
    "top_risk = or_df.sort_values(\"odds_ratio\", ascending=False).head(5)\n",
    "top_protect = or_df.sort_values(\"odds_ratio\", ascending=True).head(5)\n",
    "\n",
    "print(\"Top risk-increasing (OR>1):\")\n",
    "print(top_risk.to_string(index=False))\n",
    "print(\"\\nTop protective (OR<1):\")\n",
    "print(top_protect.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0beab59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
