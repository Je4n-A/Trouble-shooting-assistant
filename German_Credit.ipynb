{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9332a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 21)\n",
      "int64       7\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "category    1\n",
      "Name: count, dtype: int64\n",
      "class\n",
      "good    700\n",
      "bad     300\n",
      "Name: count, dtype: int64\n",
      "class\n",
      "good    70.0\n",
      "bad     30.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Trouble-shooting-assistant\\.venv\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:328: UserWarning: Multiple active versions of the dataset matching the name credit-g exist. Versions may be fundamentally different, returning version 1. Available versions:\n",
      "- version 1, status: active\n",
      "  url: https://www.openml.org/search?type=data&id=31\n",
      "- version 2, status: active\n",
      "  url: https://www.openml.org/search?type=data&id=44096\n",
      "\n",
      "  warn(warning_msg)\n"
     ]
    }
   ],
   "source": [
    "# import neccessary libraries\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "data = fetch_openml(\"credit-g\", as_frame=True, parser=\"auto\")\n",
    "df = pd.concat([data.data, data.target.rename(\"class\")], axis=1)\n",
    "\n",
    "X = df.drop(columns=[\"class\"])\n",
    "y = df[\"class\"]\n",
    "\n",
    "print(df.shape)                 # expect (1000, 21)\n",
    "print(X.dtypes.value_counts())  # see mix of categories/numerics\n",
    "print(y.value_counts())         # counts\n",
    "print((y.value_counts(normalize=True)*100).round(2))  # percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ac478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (800, 20)\n",
      "X_valid (200, 20)\n",
      "y_train (800,)\n",
      "y_valid (200,)\n"
     ]
    }
   ],
   "source": [
    "# stratified train/validation split (80/20)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "for name, arr in [(\"X_train\", X_train), (\"X_valid\", X_valid),\n",
    "                  (\"y_train\", y_train), (\"y_valid\", y_valid)]:\n",
    "    print(name, arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fbc153a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 categorical\n",
      "7 numeric\n",
      "['checking_status', 'credit_history', 'purpose', 'savings_status', 'employment', 'personal_status', 'other_parties', 'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker']\n"
     ]
    }
   ],
   "source": [
    "# Identifying which features are categorical vs numeric for X_train\n",
    "\n",
    "cat_cols = X_train.select_dtypes(include=['category','object']).columns.tolist()\n",
    "num_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print(len(cat_cols), \"categorical\"); print(len(num_cols), \"numeric\")\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "252680a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "cat_cols = ['checking_status','credit_history','purpose','savings_status','employment',\n",
    "            'personal_status','other_parties','property_magnitude','other_payment_plans',\n",
    "            'housing','job','own_telephone','foreign_worker']\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "])\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "proba_valid = clf.predict_proba(X_valid)\n",
    "idx_bad = list(clf.named_steps[\"model\"].classes_).index(\"bad\")\n",
    "p_bad = proba_valid[:, idx_bad]\n",
    "\n",
    "auc = roc_auc_score((y_valid==\"bad\").astype(int), p_bad)\n",
    "print(\"Validation ROC-AUC:\", round(auc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c56bb73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786 0.019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "y_bad = (y == \"bad\").astype(int)  # 1 = bad (positive class), 0 = good\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(clf, X, y_bad, cv=cv, scoring=\"roc_auc\")\n",
    "print(scores.mean().round(3), scores.std().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee1089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.791 0.022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400, random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "rf_clf = Pipeline([(\"prep\", preprocess), (\"model\", rf)])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(rf_clf, X, y_bad, cv=cv, scoring=\"roc_auc\")\n",
    "print(scores.mean().round(3), scores.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3b5148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20500000000000002 [[77 63]\n",
      " [ 6 54]]\n",
      "Precision: 0.46153846153846156\n",
      "Recall: 0.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "y_true = (y_valid==\"bad\").astype(int)\n",
    "best = (None, 1e18)  # (t, cost)\n",
    "for t in np.linspace(0,1,201):\n",
    "    y_pred = (p_bad >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    cost = fp*1 + fn*5\n",
    "    if cost < best[1]:\n",
    "        best = (t, cost)\n",
    "t_star = best[0]\n",
    "y_hat = (p_bad >= t_star).astype(int)\n",
    "print(t_star, confusion_matrix(y_true, y_hat))\n",
    "print(\"Precision:\", precision_score(y_true, y_hat))\n",
    "print(\"Recall:\", recall_score(y_true, y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4611c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost@0.5 = 190 cmat: [[np.int64(115), np.int64(25)], [np.int64(33), np.int64(27)]]\n",
      "51.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = (y_valid==\"bad\").astype(int)\n",
    "y_hat_05 = (p_bad >= 0.5).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_hat_05).ravel()\n",
    "print(\"cost@0.5 =\", fp + 5*fn, \"cmat:\", [[tn,fp],[fn,tp]])\n",
    "cost_default = 190\n",
    "cost_opt = 93\n",
    "reduction_pct = (cost_default - cost_opt) / cost_default * 100\n",
    "print(round(reduction_pct, 1))  # â†’ 51.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87118a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top risk-increasing (OR>1):\n",
      "                                      feature  odds_ratio\n",
      "                             purpose_used car    3.871150\n",
      "                  checking_status_no checking    2.712682\n",
      "                      other_parties_guarantor    2.670500\n",
      "credit_history_critical/other existing credit    2.324341\n",
      "                            foreign_worker_no    2.053430\n",
      "\n",
      "Top protective (OR<1):\n",
      "                   feature  odds_ratio\n",
      "         purpose_education    0.493475\n",
      "           purpose_new car    0.506342\n",
      "        checking_status_<0    0.508079\n",
      "       savings_status_<100    0.587095\n",
      "other_parties_co applicant    0.599541\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pre = clf.named_steps[\"prep\"]\n",
    "ohe = pre.named_transformers_[\"cat\"]\n",
    "# Feature names (version-safe)\n",
    "try:\n",
    "    cat_feats = ohe.get_feature_names_out(cat_cols)\n",
    "except:\n",
    "    cat_feats = ohe.get_feature_names(cat_cols)\n",
    "feat_names = list(num_cols) + list(cat_feats)\n",
    "\n",
    "coef = clf.named_steps[\"model\"].coef_.ravel()\n",
    "or_df = pd.DataFrame({\"feature\": feat_names, \"odds_ratio\": np.exp(coef)})\n",
    "\n",
    "top_risk = or_df.sort_values(\"odds_ratio\", ascending=False).head(5)\n",
    "top_protect = or_df.sort_values(\"odds_ratio\", ascending=True).head(5)\n",
    "\n",
    "print(\"Top risk-increasing (OR>1):\")\n",
    "print(top_risk.to_string(index=False))\n",
    "print(\"\\nTop protective (OR<1):\")\n",
    "print(top_protect.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0beab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score: 0.183\n",
      "Brier score (baseline): 0.21\n",
      "Brier skill score: 0.129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "y_true = (y_valid==\"bad\").astype(int)\n",
    "brier = brier_score_loss(y_true, p_bad)\n",
    "print(\"Brier score:\", round(brier, 3))\n",
    "\n",
    "p_base = np.full(y_true.shape, y_true.mean(), dtype=float)\n",
    "brier_base = brier_score_loss(y_true, p_base)\n",
    "print(\"Brier score (baseline):\", round(brier_base, 3))\n",
    "print(\"Brier skill score:\", round(1 - brier / brier_base, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481964c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated Brier: 0.176 Calibrated AUC: 0.762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score\n",
    "\n",
    "y_true = (y_valid==\"bad\").astype(int)\n",
    "\n",
    "cal = CalibratedClassifierCV(estimator=clf, method='sigmoid', cv=5)\n",
    "cal.fit(X_train, y_train)\n",
    "\n",
    "proba_cal = cal.predict_proba(X_valid)\n",
    "# find index of 'bad'\n",
    "idx_bad = list(cal.classes_).index(\"bad\")\n",
    "p_bad_cal = proba_cal[:, idx_bad]\n",
    "\n",
    "brier_cal = brier_score_loss(y_true, p_bad_cal)\n",
    "auc_cal = roc_auc_score(y_true, p_bad_cal)\n",
    "print(\"Calibrated Brier:\", round(brier_cal, 3), \"Calibrated AUC:\", round(auc_cal, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a5610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t* = 0.21 cost = 96\n",
      "cmat@t* =\n",
      " [[69 71]\n",
      " [ 5 55]]\n",
      "precision = 0.437\n",
      "recall    = 0.917\n",
      "t, cost reduction = 49.5 %\n",
      "cmat@0.5 =\n",
      " [[118  22]\n",
      " [ 33  27]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "y_true = (y_valid == \"bad\").astype(int)\n",
    "\n",
    "best_t, best_cost, best_cmat = None, float(\"inf\"), None\n",
    "for t in np.arange(0.18, 0.24, 0.001):\n",
    "    y_hat = (p_bad_cal >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "    cost = fp + 5*fn\n",
    "    if cost < best_cost:\n",
    "        best_t, best_cost = t, cost\n",
    "        best_cmat = np.array([[tn, fp], [fn, tp]])\n",
    "\n",
    "print(\"t* =\", round(best_t, 3), \"cost =\", int(best_cost))\n",
    "print(\"cmat@t* =\\n\", best_cmat)\n",
    "print(\"precision =\", round(precision_score(y_true, (p_bad_cal >= best_t)), 3))\n",
    "print(\"recall    =\", round(recall_score(y_true, (p_bad_cal >= best_t)), 3))\n",
    "print(\"t, cost reduction =\", round((190 - best_cost) / 190 * 100, 1), \"%\")\n",
    "print(\"cmat@0.5 =\\n\", confusion_matrix(y_true, (p_bad_cal >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2cbd4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 71 5 55\n"
     ]
    }
   ],
   "source": [
    "print(best_cmat[0,0], best_cmat[0,1], best_cmat[1,0], best_cmat[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc6b80a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval rate at t* = 0.37\n",
      "Default capture rate at t* = 0.917\n",
      "Expected cost at t* = 96\n",
      "Expected cost per sample at t* = 0.48\n"
     ]
    }
   ],
   "source": [
    "approval_rate = (best_cmat[0,0] + best_cmat[1,0]) / best_cmat.sum()\n",
    "print(\"Approval rate at t* =\", round(approval_rate, 3))\n",
    "default_capture_rate = best_cmat[1,1] / (best_cmat[1,1] + best_cmat[1,0])\n",
    "print(\"Default capture rate at t* =\", round(default_capture_rate, 3))\n",
    "Expected_cost = best_cmat[0,1] + best_cmat[1,0] * 5 \n",
    "Expected_cost_per = Expected_cost / best_cmat.sum()\n",
    "print(\"Expected cost at t* =\", round(Expected_cost, 2))\n",
    "print(\"Expected cost per sample at t* =\", round(Expected_cost_per, 4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
